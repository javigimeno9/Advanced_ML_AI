{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAKmkd055Gu0"
      },
      "source": [
        "# **Library Installation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XImbxY3F5CXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f8fe2a-3229-43d6-8fb6-8ef0408ed5ac"
      },
      "source": [
        "#pip installation\n",
        "!pip install -U spacy #Spacy library\n",
        "!python -m spacy download en_core_web_sm #English\n",
        "!python -m spacy download xx_ent_wiki_sm #Multilanguage\n",
        "!python -m spacy download es_core_news_sm #Spanish\n",
        "!python -m spacy download en_core_web_lg #English\n",
        "!python -m spacy download xx_ent_wiki_lg #Multilanguage\n",
        "!python -m spacy download es_core_news_lg #Spanish"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.2)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.2\n",
            "    Uninstalling spacy-3.7.2:\n",
            "      Successfully uninstalled spacy-3.7.2\n",
            "Successfully installed spacy-3.7.4\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting xx-ent-wiki-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.7.0/xx_ent_wiki_sm-3.7.0-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from xx-ent-wiki-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: xx-ent-wiki-sm\n",
            "Successfully installed xx-ent-wiki-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('xx_ent_wiki_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "\u001b[38;5;1m✘ No compatible package found for 'xx_ent_wiki_lg' (spaCy v3.7.4)\u001b[0m\n",
            "\n",
            "Collecting es-core-news-lg==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.7.0/es_core_news_lg-3.7.0-py3-none-any.whl (568.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.0/568.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-lg==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-lg==3.7.0) (2.1.5)\n",
            "Installing collected packages: es-core-news-lg\n",
            "Successfully installed es-core-news-lg-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsPQTTEzciNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e364b1-bb9f-4754-bccc-b323b6129a0d"
      },
      "source": [
        "!pip install --user -U nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZGiF-S95WOq"
      },
      "source": [
        "#importing libraries\n",
        "import spacy\n",
        "import nltk\n",
        "import pandas\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQLF27y8VYGB"
      },
      "source": [
        "## 0. Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Akm0t0U5qni",
        "outputId": "a92d643c-914c-4a61-c476-9647f63e1b1d"
      },
      "source": [
        "with open (\"/content/aliceinwonderland.txt\", \"r\") as f:\n",
        "  text = f.read().replace(\"\\n\\n\", \" \").replace(\"\\n\",\" \") #taking out in between sentences spaces and double spaces\n",
        "  #print(text)\n",
        "  chapters = text.split(\"CHAPTER \")[1:] #starting from position number 2 deleting the first space\n",
        "  #print(chapters)\n",
        "  print(chapters[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "II. The Pool of Tears  “Curiouser and curiouser!” cried Alice (she was so much surprised, that for the moment she quite forgot how to speak good English); “now I’m opening out like the largest telescope that ever was! Good-bye, feet!” (for when she looked down at her feet, they seemed to be almost out of sight, they were getting so far off). “Oh, my poor little feet, I wonder who will put on your shoes and stockings for you now, dears? I’m sure _I_ shan’t be able! I shall be a great deal too far off to trouble myself about you: you must manage the best way you can;—but I must be kind to them,” thought Alice, “or perhaps they won’t walk the way I want to go! Let me see: I’ll give them a new pair of boots every Christmas.” And she went on planning to herself how she would manage it. “They must go by the carrier,” she thought; “and how funny it’ll seem, sending presents to one’s own feet! And how odd the directions will look!      _Alice’s Right Foot, Esq., Hearthrug, near the Fender,_ (_with      Alice’s love_). Oh dear, what nonsense I’m talking!” Just then her head struck against the roof of the hall: in fact she was now more than nine feet high, and she at once took up the little golden key and hurried off to the garden door. Poor Alice! It was as much as she could do, lying down on one side, to look through into the garden with one eye; but to get through was more hopeless than ever: she sat down and began to cry again. “You ought to be ashamed of yourself,” said Alice, “a great girl like you,” (she might well say this), “to go on crying in this way! Stop this moment, I tell you!” But she went on all the same, shedding gallons of tears, until there was a large pool all round her, about four inches deep and reaching half down the hall. After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came, “Oh! the Duchess, the Duchess! Oh! won’t she be savage if I’ve kept her waiting!” Alice felt so desperate that she was ready to ask help of any one; so, when the Rabbit came near her, she began, in a low, timid voice, “If you please, sir—” The Rabbit started violently, dropped the white kid gloves and the fan, and skurried away into the darkness as hard as he could go. Alice took up the fan and gloves, and, as the hall was very hot, she kept fanning herself all the time she went on talking: “Dear, dear! How queer everything is to-day! And yesterday things went on just as usual. I wonder if I’ve been changed in the night? Let me think: was I the same when I got up this morning? I almost think I can remember feeling a little different. But if I’m not the same, the next question is, Who in the world am I? Ah, _that’s_ the great puzzle!” And she began thinking over all the children she knew that were of the same age as herself, to see if she could have been changed for any of them. “I’m sure I’m not Ada,” she said, “for her hair goes in such long ringlets, and mine doesn’t go in ringlets at all; and I’m sure I can’t be Mabel, for I know all sorts of things, and she, oh! she knows such a very little! Besides, _she’s_ she, and _I’m_ I, and—oh dear, how puzzling it all is! I’ll try if I know all the things I used to know. Let me see: four times five is twelve, and four times six is thirteen, and four times seven is—oh dear! I shall never get to twenty at that rate! However, the Multiplication Table doesn’t signify: let’s try Geography. London is the capital of Paris, and Paris is the capital of Rome, and Rome—no, _that’s_ all wrong, I’m certain! I must have been changed for Mabel! I’ll try and say ‘_How doth the little_—’” and she crossed her hands on her lap as if she were saying lessons, and began to repeat it, but her voice sounded hoarse and strange, and the words did not come the same as they used to do:— “How doth the little crocodile     Improve his shining tail, And pour the waters of the Nile     On every golden scale! “How cheerfully he seems to grin,     How neatly spread his claws, And welcome little fishes in     With gently smiling jaws!”  “I’m sure those are not the right words,” said poor Alice, and her eyes filled with tears again as she went on, “I must be Mabel after all, and I shall have to go and live in that poky little house, and have next to no toys to play with, and oh! ever so many lessons to learn! No, I’ve made up my mind about it; if I’m Mabel, I’ll stay down here! It’ll be no use their putting their heads down and saying ‘Come up again, dear!’ I shall only look up and say ‘Who am I then? Tell me that first, and then, if I like being that person, I’ll come up: if not, I’ll stay down here till I’m somebody else’—but, oh dear!” cried Alice, with a sudden burst of tears, “I do wish they _would_ put their heads down! I am so _very_ tired of being all alone here!” As she said this she looked down at her hands, and was surprised to see that she had put on one of the Rabbit’s little white kid gloves while she was talking. “How _can_ I have done that?” she thought. “I must be growing small again.” She got up and went to the table to measure herself by it, and found that, as nearly as she could guess, she was now about two feet high, and was going on shrinking rapidly: she soon found out that the cause of this was the fan she was holding, and she dropped it hastily, just in time to avoid shrinking away altogether. “That _was_ a narrow escape!” said Alice, a good deal frightened at the sudden change, but very glad to find herself still in existence; “and now for the garden!” and she ran with all speed back to the little door: but, alas! the little door was shut again, and the little golden key was lying on the glass table as before, “and things are worse than ever,” thought the poor child, “for I never was so small as this before, never! And I declare it’s too bad, that it is!” As she said these words her foot slipped, and in another moment, splash! she was up to her chin in salt water. Her first idea was that she had somehow fallen into the sea, “and in that case I can go back by railway,” she said to herself. (Alice had been to the seaside once in her life, and had come to the general conclusion, that wherever you go to on the English coast you find a number of bathing machines in the sea, some children digging in the sand with wooden spades, then a row of lodging houses, and behind them a railway station.) However, she soon made out that she was in the pool of tears which she had wept when she was nine feet high. “I wish I hadn’t cried so much!” said Alice, as she swam about, trying to find her way out. “I shall be punished for it now, I suppose, by being drowned in my own tears! That _will_ be a queer thing, to be sure! However, everything is queer to-day.” Just then she heard something splashing about in the pool a little way off, and she swam nearer to make out what it was: at first she thought it must be a walrus or hippopotamus, but then she remembered how small she was now, and she soon made out that it was only a mouse that had slipped in like herself. “Would it be of any use, now,” thought Alice, “to speak to this mouse? Everything is so out-of-the-way down here, that I should think very likely it can talk: at any rate, there’s no harm in trying.” So she began: “O Mouse, do you know the way out of this pool? I am very tired of swimming about here, O Mouse!” (Alice thought this must be the right way of speaking to a mouse: she had never done such a thing before, but she remembered having seen in her brother’s Latin Grammar, “A mouse—of a mouse—to a mouse—a mouse—O mouse!”) The Mouse looked at her rather inquisitively, and seemed to her to wink with one of its little eyes, but it said nothing. “Perhaps it doesn’t understand English,” thought Alice; “I daresay it’s a French mouse, come over with William the Conqueror.” (For, with all her knowledge of history, Alice had no very clear notion how long ago anything had happened.) So she began again: “Où est ma chatte?” which was the first sentence in her French lesson-book. The Mouse gave a sudden leap out of the water, and seemed to quiver all over with fright. “Oh, I beg your pardon!” cried Alice hastily, afraid that she had hurt the poor animal’s feelings. “I quite forgot you didn’t like cats.” “Not like cats!” cried the Mouse, in a shrill, passionate voice. “Would _you_ like cats if you were me?” “Well, perhaps not,” said Alice in a soothing tone: “don’t be angry about it. And yet I wish I could show you our cat Dinah: I think you’d take a fancy to cats if you could only see her. She is such a dear quiet thing,” Alice went on, half to herself, as she swam lazily about in the pool, “and she sits purring so nicely by the fire, licking her paws and washing her face—and she is such a nice soft thing to nurse—and she’s such a capital one for catching mice—oh, I beg your pardon!” cried Alice again, for this time the Mouse was bristling all over, and she felt certain it must be really offended. “We won’t talk about her any more if you’d rather not.” “We indeed!” cried the Mouse, who was trembling down to the end of his tail. “As if _I_ would talk on such a subject! Our family always _hated_ cats: nasty, low, vulgar things! Don’t let me hear the name again!” “I won’t indeed!” said Alice, in a great hurry to change the subject of conversation. “Are you—are you fond—of—of dogs?” The Mouse did not answer, so Alice went on eagerly: “There is such a nice little dog near our house I should like to show you! A little bright-eyed terrier, you know, with oh, such long curly brown hair! And it’ll fetch things when you throw them, and it’ll sit up and beg for its dinner, and all sorts of things—I can’t remember half of them—and it belongs to a farmer, you know, and he says it’s so useful, it’s worth a hundred pounds! He says it kills all the rats and—oh dear!” cried Alice in a sorrowful tone, “I’m afraid I’ve offended it again!” For the Mouse was swimming away from her as hard as it could go, and making quite a commotion in the pool as it went. So she called softly after it, “Mouse dear! Do come back again, and we won’t talk about cats or dogs either, if you don’t like them!” When the Mouse heard this, it turned round and swam slowly back to her: its face was quite pale (with passion, Alice thought), and it said in a low trembling voice, “Let us get to the shore, and then I’ll tell you my history, and you’ll understand why it is I hate cats and dogs.” It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWzT6K7XVxX4"
      },
      "source": [
        "## 1. Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5qKPpnr6IoI"
      },
      "source": [
        "#we load the small trained model | medium: en_core_web_sm | large: en_core_web_lg |\n",
        "#More models info: https://spacy.io/models/en\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GjxRY6UX_IA",
        "outputId": "44633c99-4517-4dc8-a459-8a9472af13a4"
      },
      "source": [
        "# creating an object\n",
        "chapter1 = chapters[0]\n",
        "doc = nlp(chapter1) #lets generate a doc variable with our chapter1\n",
        "sentences = list(doc.sents)\n",
        "print(sentences[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "much out of the way to hear the Rabbit say to itself, “Oh dear!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmbrZgxlXseB",
        "outputId": "cb0b3546-f052-4e25-8ac1-7faa2bca2fbf"
      },
      "source": [
        "#lets print the entities from a sentence\n",
        "sentence = sentences[3] #we define a specific sentence\n",
        "ents = list(sentence.ents) #we extract the entities from the sentence\n",
        "print(ents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Alice]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ycSDFdDdrAd",
        "outputId": "c67ff971-e434-4b0b-c11a-42a4912d1818"
      },
      "source": [
        "#lets print the entities and the metadata for the entities\n",
        "print(ents[0].label)\n",
        "print(ents[0].label_)\n",
        "print(ents[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380\n",
            "PERSON\n",
            "Alice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MXbkou5eP16",
        "outputId": "5447aefb-ecba-496d-8c7f-f06f3c8f61a4"
      },
      "source": [
        "#based on that metadata, we can do some interesting things like bringing a list of people\n",
        "\n",
        "#lets first bring all the chapter1 entities\n",
        "ents = list(doc.ents)\n",
        "\n",
        "#we generate a variable people as a list\n",
        "people = []\n",
        "\n",
        "#we generate a for loop that generates a list of people\n",
        "for ent in ents:\n",
        "  if ent.label_ == \"PERSON\":\n",
        "    people.append(ent)\n",
        "print(people)\n",
        "\n",
        "#mostrar la mejora que hay con el modelo lg y el descenso de los false positives\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I. Down, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice, Alice]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_S0qCog5v12"
      },
      "source": [
        "## 2. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEGdxfr9h7nI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ff15e7-cf45-44c8-a5d2-ff60ef60a290"
      },
      "source": [
        "#we will work with this sentence so we generate a variable sentence2\n",
        "sentence2 = sentences[1]\n",
        "print(sentence2)\n",
        "print(\"----------------------\")\n",
        "#we use a for loop to obtain the sentence words (tokens)\n",
        "for token in sentence2:\n",
        "  print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Rabbit-Hole  Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, “and what is the use of a book,” thought Alice “without pictures or conversations?”\n",
            "----------------------\n",
            "the\n",
            "Rabbit\n",
            "-\n",
            "Hole\n",
            " \n",
            "Alice\n",
            "was\n",
            "beginning\n",
            "to\n",
            "get\n",
            "very\n",
            "tired\n",
            "of\n",
            "sitting\n",
            "by\n",
            "her\n",
            "sister\n",
            "on\n",
            "the\n",
            "bank\n",
            ",\n",
            "and\n",
            "of\n",
            "having\n",
            "nothing\n",
            "to\n",
            "do\n",
            ":\n",
            "once\n",
            "or\n",
            "twice\n",
            "she\n",
            "had\n",
            "peeped\n",
            "into\n",
            "the\n",
            "book\n",
            "her\n",
            "sister\n",
            "was\n",
            "reading\n",
            ",\n",
            "but\n",
            "it\n",
            "had\n",
            "no\n",
            "pictures\n",
            "or\n",
            "conversations\n",
            "in\n",
            "it\n",
            ",\n",
            "“\n",
            "and\n",
            "what\n",
            "is\n",
            "the\n",
            "use\n",
            "of\n",
            "a\n",
            "book\n",
            ",\n",
            "”\n",
            "thought\n",
            "Alice\n",
            "“\n",
            "without\n",
            "pictures\n",
            "or\n",
            "conversations\n",
            "?\n",
            "”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqGDsrnFiCHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5d6f09-0acd-4bc7-83f4-f8f46ce1faa3"
      },
      "source": [
        "#How do we add the part of speech? Lets obtain the metadata of each token\n",
        "for token in sentence2:\n",
        "  print(token.text, token.pos_) #we pass arguments \"text\" to get the token and \"pos_\" to get the part of speech (without _ we will get a number)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the DET\n",
            "Rabbit NOUN\n",
            "- PUNCT\n",
            "Hole PROPN\n",
            "  SPACE\n",
            "Alice PROPN\n",
            "was AUX\n",
            "beginning VERB\n",
            "to PART\n",
            "get VERB\n",
            "very ADV\n",
            "tired ADJ\n",
            "of ADP\n",
            "sitting VERB\n",
            "by ADP\n",
            "her PRON\n",
            "sister NOUN\n",
            "on ADP\n",
            "the DET\n",
            "bank NOUN\n",
            ", PUNCT\n",
            "and CCONJ\n",
            "of ADP\n",
            "having VERB\n",
            "nothing PRON\n",
            "to PART\n",
            "do VERB\n",
            ": PUNCT\n",
            "once ADV\n",
            "or CCONJ\n",
            "twice ADV\n",
            "she PRON\n",
            "had AUX\n",
            "peeped VERB\n",
            "into ADP\n",
            "the DET\n",
            "book NOUN\n",
            "her PRON\n",
            "sister NOUN\n",
            "was AUX\n",
            "reading VERB\n",
            ", PUNCT\n",
            "but CCONJ\n",
            "it PRON\n",
            "had VERB\n",
            "no DET\n",
            "pictures NOUN\n",
            "or CCONJ\n",
            "conversations NOUN\n",
            "in ADP\n",
            "it PRON\n",
            ", PUNCT\n",
            "“ PUNCT\n",
            "and CCONJ\n",
            "what PRON\n",
            "is AUX\n",
            "the DET\n",
            "use NOUN\n",
            "of ADP\n",
            "a DET\n",
            "book NOUN\n",
            ", PUNCT\n",
            "” PUNCT\n",
            "thought VERB\n",
            "Alice PROPN\n",
            "“ PUNCT\n",
            "without ADP\n",
            "pictures NOUN\n",
            "or CCONJ\n",
            "conversations NOUN\n",
            "? PUNCT\n",
            "” PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words"
      ],
      "metadata": {
        "id": "o1Jo0TK1GHnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qz0EkrAGB1i",
        "outputId": "2ceb9a45-4056-4a45-bb10-73096cd9e362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#English example\n",
        "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(\"Stop words: \", stop_words)\n",
        "\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(\"Tokenized Sentence: \", word_tokens)\n",
        "print(\"Filtered Sentence: \", filtered_sentence)"
      ],
      "metadata": {
        "id": "mvwEzS9dBUOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90841f29-2d5d-4645-90d8-0d482fe578e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words:  {'eres', 'del', 'están', 'tendrían', 'hubiste', 'estás', 'algunas', 'hubiese', 'sois', 'hubieran', 'hayamos', 'antes', 'tuvo', 'tuve', 'estuvierais', 'tuya', 'nosotros', 'fuéramos', 'unos', 'tendríamos', 'tuyos', 'siente', 'suyas', 'e', 'tendríais', 'otra', 'ya', 'estará', 'habidos', 'le', 'hay', 'vuestras', 'teniendo', 'habéis', 'hubo', 'tenidos', 'vosotros', 'al', 'hubiésemos', 'estaréis', 'otros', 'estuviésemos', 'tuviésemos', 'hemos', 'ha', 'como', 'tuyas', 'tú', 'para', 'se', 'tuvieseis', 'habido', 'muy', 'ellos', 'tuviesen', 'por', 'estada', 'ni', 'porque', 'habrán', 'míos', 'tuviste', 'sin', 'suyo', 'estáis', 'estadas', 'él', 'hubieron', 'sentid', 'quienes', 'hubieras', 'todos', 'tenía', 'hubiesen', 'fuesen', 'vuestra', 'tendréis', 'otras', 'son', 'suya', 'tengas', 'será', 'sería', 'la', 'sentidas', 'fue', 'estuviéramos', 'estado', 'vuestros', 'estuvimos', 'tendrás', 'tuvieran', 'sus', 'he', 'habréis', 'esa', 'somos', 'habrían', 'teníais', 'estábamos', 'entre', 'sentido', 'vosotras', 'otro', 'tuvieses', 'tuvieras', 'estén', 'tenga', 'pero', 'estaríais', 'sintiendo', 'estarías', 'seréis', 'habremos', 'ella', 'estuviste', 'el', 'eras', 'ellas', 'fuiste', 'tienen', 'estar', 'estarán', 'fuerais', 'tenida', 'tendremos', 'tendrán', 'y', 'esta', 'mis', 'os', 'tendré', 'en', 'ante', 'estabas', 'hayas', 'estados', 'habíais', 'muchos', 'contra', 'fueron', 'esos', 'habíamos', 'estamos', 'durante', 'fueseis', 'fuera', 'algo', 'teníamos', 'hubisteis', 'tu', 'sea', 'habríamos', 'nuestros', 'yo', 'soy', 'seríamos', 'nuestra', 'habiendo', 'fui', 'hube', 'han', 'estarían', 'las', 'qué', 'estuvieseis', 'tendría', 'era', 'ese', 'estaría', 'con', 'un', 'esté', 'esas', 'suyos', 'estuviese', 'poco', 'tened', 'tanto', 'no', 'tuyo', 'quien', 'tengamos', 'estos', 'donde', 'tuviera', 'cual', 'sentidos', 'habré', 'hubiera', 'mi', 'serían', 'estas', 'tendrá', 'vuestro', 'me', 'sentida', 'tuvisteis', 'había', 'estaremos', 'éramos', 'nada', 'hubiéramos', 'habidas', 'hasta', 'estuve', 'es', 'estaban', 'tengo', 'hubimos', 'su', 'habrás', 'estaríamos', 'tienes', 'lo', 'algunos', 'a', 'todo', 'tiene', 'nos', 'erais', 'tuvierais', 'sean', 'estoy', 'estéis', 'o', 'también', 'habrías', 'nuestro', 'estuvieran', 'que', 'habías', 'serías', 'estuviera', 'nuestras', 'estuvisteis', 'estuvieron', 'hubierais', 'tengan', 'fuimos', 'uno', 'seáis', 'fueras', 'estuvo', 'sobre', 'tengáis', 'habrá', 'estaré', 'tus', 'mí', 'serán', 'te', 'nosotras', 'estés', 'tuviéramos', 'tuviese', 'mías', 'tenemos', 'fuisteis', 'estemos', 'habríais', 'estando', 'tuvimos', 'mía', 'les', 'eran', 'estuviesen', 'seríais', 'serás', 'ti', 'haya', 'hayáis', 'seremos', 'estarás', 'eso', 'desde', 'tenéis', 'fueses', 'estaba', 'estad', 'de', 'cuando', 'hayan', 'habría', 'tuvieron', 'una', 'tenías', 'tenían', 'fuésemos', 'los', 'mucho', 'hubieses', 'hubieseis', 'más', 'seas', 'seré', 'estuvieses', 'tenidas', 'estabais', 'fuese', 'esto', 'habían', 'tenido', 'fueran', 'estuvieras', 'habida', 'este', 'está', 'has', 'sí', 'tendrías', 'mío', 'seamos'}\n",
            "Tokenized Sentence:  ['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
            "Filtered Sentence:  ['This', 'is', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Spanish example\n",
        "example_sent = \"La coalición de conservadores, posfascistas y populistas, liderada por Giorgia Meloni, logra el 44% de los votos tanto en la Cámara de Diputados como en el Senado, con el 99,9% de los votos escrutados.\"\n",
        "\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "print(\"Stop words: \", stop_words)\n",
        "\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(\"Tokenized Sentence: \", word_tokens)\n",
        "print(\"Filtered Sentence: \", filtered_sentence)"
      ],
      "metadata": {
        "id": "22vTmWZ0GdI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6ae7ef-1d77-4d25-babf-105a756a9b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words:  {'eres', 'del', 'están', 'tendrían', 'hubiste', 'estás', 'algunas', 'hubiese', 'sois', 'hubieran', 'hayamos', 'antes', 'tuvo', 'tuve', 'estuvierais', 'tuya', 'nosotros', 'fuéramos', 'unos', 'tendríamos', 'tuyos', 'siente', 'suyas', 'e', 'tendríais', 'otra', 'ya', 'estará', 'habidos', 'le', 'hay', 'vuestras', 'teniendo', 'habéis', 'hubo', 'tenidos', 'vosotros', 'al', 'hubiésemos', 'estaréis', 'otros', 'estuviésemos', 'tuviésemos', 'hemos', 'ha', 'como', 'tuyas', 'tú', 'para', 'se', 'tuvieseis', 'habido', 'muy', 'ellos', 'tuviesen', 'por', 'estada', 'ni', 'porque', 'habrán', 'míos', 'tuviste', 'sin', 'suyo', 'estáis', 'estadas', 'él', 'hubieron', 'sentid', 'quienes', 'hubieras', 'todos', 'tenía', 'hubiesen', 'fuesen', 'vuestra', 'tendréis', 'otras', 'son', 'suya', 'tengas', 'será', 'sería', 'la', 'sentidas', 'fue', 'estuviéramos', 'estado', 'vuestros', 'estuvimos', 'tendrás', 'tuvieran', 'sus', 'he', 'habréis', 'esa', 'somos', 'habrían', 'teníais', 'estábamos', 'entre', 'sentido', 'vosotras', 'otro', 'tuvieses', 'tuvieras', 'estén', 'tenga', 'pero', 'estaríais', 'sintiendo', 'estarías', 'seréis', 'habremos', 'ella', 'estuviste', 'el', 'eras', 'ellas', 'fuiste', 'tienen', 'estar', 'estarán', 'fuerais', 'tenida', 'tendremos', 'tendrán', 'y', 'esta', 'mis', 'os', 'tendré', 'en', 'ante', 'estabas', 'hayas', 'estados', 'habíais', 'muchos', 'contra', 'fueron', 'esos', 'habíamos', 'estamos', 'durante', 'fueseis', 'fuera', 'algo', 'teníamos', 'hubisteis', 'tu', 'sea', 'habríamos', 'nuestros', 'yo', 'soy', 'seríamos', 'nuestra', 'habiendo', 'fui', 'hube', 'han', 'estarían', 'las', 'qué', 'estuvieseis', 'tendría', 'era', 'ese', 'estaría', 'con', 'un', 'esté', 'esas', 'suyos', 'estuviese', 'poco', 'tened', 'tanto', 'no', 'tuyo', 'quien', 'tengamos', 'estos', 'donde', 'tuviera', 'cual', 'sentidos', 'habré', 'hubiera', 'mi', 'serían', 'estas', 'tendrá', 'vuestro', 'me', 'sentida', 'tuvisteis', 'había', 'estaremos', 'éramos', 'nada', 'hubiéramos', 'habidas', 'hasta', 'estuve', 'es', 'estaban', 'tengo', 'hubimos', 'su', 'habrás', 'estaríamos', 'tienes', 'lo', 'algunos', 'a', 'todo', 'tiene', 'nos', 'erais', 'tuvierais', 'sean', 'estoy', 'estéis', 'o', 'también', 'habrías', 'nuestro', 'estuvieran', 'que', 'habías', 'serías', 'estuviera', 'nuestras', 'estuvisteis', 'estuvieron', 'hubierais', 'tengan', 'fuimos', 'uno', 'seáis', 'fueras', 'estuvo', 'sobre', 'tengáis', 'habrá', 'estaré', 'tus', 'mí', 'serán', 'te', 'nosotras', 'estés', 'tuviéramos', 'tuviese', 'mías', 'tenemos', 'fuisteis', 'estemos', 'habríais', 'estando', 'tuvimos', 'mía', 'les', 'eran', 'estuviesen', 'seríais', 'serás', 'ti', 'haya', 'hayáis', 'seremos', 'estarás', 'eso', 'desde', 'tenéis', 'fueses', 'estaba', 'estad', 'de', 'cuando', 'hayan', 'habría', 'tuvieron', 'una', 'tenías', 'tenían', 'fuésemos', 'los', 'mucho', 'hubieses', 'hubieseis', 'más', 'seas', 'seré', 'estuvieses', 'tenidas', 'estabais', 'fuese', 'esto', 'habían', 'tenido', 'fueran', 'estuvieras', 'habida', 'este', 'está', 'has', 'sí', 'tendrías', 'mío', 'seamos'}\n",
            "Tokenized Sentence:  ['La', 'coalición', 'de', 'conservadores', ',', 'posfascistas', 'y', 'populistas', ',', 'liderada', 'por', 'Giorgia', 'Meloni', ',', 'logra', 'el', '44', '%', 'de', 'los', 'votos', 'tanto', 'en', 'la', 'Cámara', 'de', 'Diputados', 'como', 'en', 'el', 'Senado', ',', 'con', 'el', '99,9', '%', 'de', 'los', 'votos', 'escrutados', '.']\n",
            "Filtered Sentence:  ['La', 'coalición', 'conservadores', ',', 'posfascistas', 'populistas', ',', 'liderada', 'Giorgia', 'Meloni', ',', 'logra', '44', '%', 'votos', 'Cámara', 'Diputados', 'Senado', ',', '99,9', '%', 'votos', 'escrutados', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaRDgUalaFDe"
      },
      "source": [
        "## 3. Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpRXL6FUjETB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2d97df-f5ea-48d0-a9bb-299164bfaa4c"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8WWozV9aZ7T"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "ls = LancasterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_mu7pPNbw8W",
        "outputId": "72917e79-5529-4753-fc76-d915cbca7bc7"
      },
      "source": [
        "print('Porter Stemmer:')\n",
        "print(ps.stem('cats'))\n",
        "print(ps.stem('trouble'))\n",
        "print(ps.stem('troubling'))\n",
        "print(ps.stem('troubled'))\n",
        "\n",
        "print('Lancaster Stemmer:')\n",
        "print(ls.stem('cats'))\n",
        "print(ls.stem('trouble'))\n",
        "print(ls.stem('troubling'))\n",
        "print(ls.stem('troubled'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer:\n",
            "cat\n",
            "troubl\n",
            "troubl\n",
            "troubl\n",
            "Lancaster Stemmer:\n",
            "cat\n",
            "troubl\n",
            "troubl\n",
            "troubl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qPT0AQcgd-O",
        "outputId": "2ddf4985-e749-4af8-9af0-2f47bf09e2e8"
      },
      "source": [
        "word_list = ['enemy', 'fellowship', 'friends', 'friendships', 'stabilize', 'destabilize', 'misunderstanding', 'road', 'sunlight', 'football']\n",
        "print('{0:20}{1:20}{2:20}'.format('Word','Porter Stemmer','Lancaster Stemmer'))\n",
        "\n",
        "for word in word_list:\n",
        "  print('{0:20}{1:20}{2:20}'.format(word,ps.stem(word),ls.stem(word)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Lancaster Stemmer   \n",
            "enemy               enemi               enemy               \n",
            "fellowship          fellowship          fellow              \n",
            "friends             friend              friend              \n",
            "friendships         friendship          friend              \n",
            "stabilize           stabil              stabl               \n",
            "destabilize         destabil            dest                \n",
            "misunderstanding    misunderstand       misunderstand       \n",
            "road                road                road                \n",
            "sunlight            sunlight            sunlight            \n",
            "football            footbal             footbal             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flmdhqHHaiTy",
        "outputId": "aaa7669f-fea6-4ce8-a8c1-b0e91ee31f1c"
      },
      "source": [
        "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
        "\n",
        "for w in example_words:\n",
        "    print(ps.stem(w))\n",
        "    print(\"-----------\")\n",
        "    print(ls.stem(w))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python\n",
            "-----------\n",
            "python\n",
            "python\n",
            "-----------\n",
            "python\n",
            "python\n",
            "-----------\n",
            "python\n",
            "python\n",
            "-----------\n",
            "python\n",
            "pythonli\n",
            "-----------\n",
            "python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxRmFrv3awIi",
        "outputId": "ec789a54-cc91-46a5-b8c6-955d9eeb6526"
      },
      "source": [
        "new_text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\"\n",
        "\n",
        "words = word_tokenize(new_text)\n",
        "\n",
        "for w in words:\n",
        "    print(ps.stem(w))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it\n",
            "is\n",
            "import\n",
            "to\n",
            "by\n",
            "veri\n",
            "pythonli\n",
            "while\n",
            "you\n",
            "are\n",
            "python\n",
            "with\n",
            "python\n",
            ".\n",
            "all\n",
            "python\n",
            "have\n",
            "python\n",
            "poorli\n",
            "at\n",
            "least\n",
            "onc\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysdBCyrcf7QO"
      },
      "source": [
        "### 4. Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QK5Q6hP1S3x",
        "outputId": "7de2abad-78dc-4345-83c1-7d142738c533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHlX9LMCb7eP",
        "outputId": "bb164d34-50a8-44ef-af56-deea33d30f98"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "new_sentence = 'London is the capital and largest city of England, and the United Kingdom, with a population of around 8.8 million,[1] and the largest city in Western Europe by metropolitan area, with a population of 14.8 million.[9][note 1] It stands on the River Thames in south-east England at the head of a 50-mile (80 km) estuary down to the North Sea and has been a major settlement for nearly two millennia.'\n",
        "#new_sentence = 'Diego Armando Maradona was an Argentine professional football player and manager. Widely regarded as one of the greatest players in the history of the sport, he was one of the two joint winners of the FIFA Player of the 20th Century award.'\n",
        "punctuations = '?:!.,:;()'\n",
        "new_sentence_words = nltk.word_tokenize(new_sentence)\n",
        "\n",
        "for word in new_sentence_words:\n",
        "  if word in punctuations:\n",
        "    new_sentence_words.remove(word)\n",
        "\n",
        "new_sentence_words\n",
        "print('{0:20}{1:20}'.format('Word','Lemma'))\n",
        "for word in new_sentence_words:\n",
        "  print('{0:20}{1:20}'.format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Lemma               \n",
            "London              London              \n",
            "is                  is                  \n",
            "the                 the                 \n",
            "capital             capital             \n",
            "and                 and                 \n",
            "largest             largest             \n",
            "city                city                \n",
            "of                  of                  \n",
            "England             England             \n",
            "and                 and                 \n",
            "the                 the                 \n",
            "United              United              \n",
            "Kingdom             Kingdom             \n",
            "with                with                \n",
            "a                   a                   \n",
            "population          population          \n",
            "of                  of                  \n",
            "around              around              \n",
            "8.8                 8.8                 \n",
            "million             million             \n",
            "[                   [                   \n",
            "1                   1                   \n",
            "]                   ]                   \n",
            "and                 and                 \n",
            "the                 the                 \n",
            "largest             largest             \n",
            "city                city                \n",
            "in                  in                  \n",
            "Western             Western             \n",
            "Europe              Europe              \n",
            "by                  by                  \n",
            "metropolitan        metropolitan        \n",
            "area                area                \n",
            "with                with                \n",
            "a                   a                   \n",
            "population          population          \n",
            "of                  of                  \n",
            "14.8                14.8                \n",
            "million             million             \n",
            "[                   [                   \n",
            "9                   9                   \n",
            "]                   ]                   \n",
            "[                   [                   \n",
            "note                note                \n",
            "1                   1                   \n",
            "]                   ]                   \n",
            "It                  It                  \n",
            "stands              stand               \n",
            "on                  on                  \n",
            "the                 the                 \n",
            "River               River               \n",
            "Thames              Thames              \n",
            "in                  in                  \n",
            "south-east          south-east          \n",
            "England             England             \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "head                head                \n",
            "of                  of                  \n",
            "a                   a                   \n",
            "50-mile             50-mile             \n",
            "80                  80                  \n",
            "km                  km                  \n",
            "estuary             estuary             \n",
            "down                down                \n",
            "to                  to                  \n",
            "the                 the                 \n",
            "North               North               \n",
            "Sea                 Sea                 \n",
            "and                 and                 \n",
            "has                 ha                  \n",
            "been                been                \n",
            "a                   a                   \n",
            "major               major               \n",
            "settlement          settlement          \n",
            "for                 for                 \n",
            "nearly              nearly              \n",
            "two                 two                 \n",
            "millennia           millennium          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mRrKwIRitV9",
        "outputId": "51a5e29c-b301-4adc-87d6-5af4e74d5bb7"
      },
      "source": [
        "for word in new_sentence_words:\n",
        "  print('{0:20}{1:20}'.format(word,wordnet_lemmatizer.lemmatize(word, pos='v')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "London              London              \n",
            "is                  be                  \n",
            "the                 the                 \n",
            "capital             capital             \n",
            "and                 and                 \n",
            "largest             largest             \n",
            "city                city                \n",
            "of                  of                  \n",
            "England             England             \n",
            "and                 and                 \n",
            "the                 the                 \n",
            "United              United              \n",
            "Kingdom             Kingdom             \n",
            "with                with                \n",
            "a                   a                   \n",
            "population          population          \n",
            "of                  of                  \n",
            "around              around              \n",
            "8.8                 8.8                 \n",
            "million             million             \n",
            "[                   [                   \n",
            "1                   1                   \n",
            "]                   ]                   \n",
            "and                 and                 \n",
            "the                 the                 \n",
            "largest             largest             \n",
            "city                city                \n",
            "in                  in                  \n",
            "Western             Western             \n",
            "Europe              Europe              \n",
            "by                  by                  \n",
            "metropolitan        metropolitan        \n",
            "area                area                \n",
            "with                with                \n",
            "a                   a                   \n",
            "population          population          \n",
            "of                  of                  \n",
            "14.8                14.8                \n",
            "million             million             \n",
            "[                   [                   \n",
            "9                   9                   \n",
            "]                   ]                   \n",
            "[                   [                   \n",
            "note                note                \n",
            "1                   1                   \n",
            "]                   ]                   \n",
            "It                  It                  \n",
            "stands              stand               \n",
            "on                  on                  \n",
            "the                 the                 \n",
            "River               River               \n",
            "Thames              Thames              \n",
            "in                  in                  \n",
            "south-east          south-east          \n",
            "England             England             \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "head                head                \n",
            "of                  of                  \n",
            "a                   a                   \n",
            "50-mile             50-mile             \n",
            "80                  80                  \n",
            "km                  km                  \n",
            "estuary             estuary             \n",
            "down                down                \n",
            "to                  to                  \n",
            "the                 the                 \n",
            "North               North               \n",
            "Sea                 Sea                 \n",
            "and                 and                 \n",
            "has                 have                \n",
            "been                be                  \n",
            "a                   a                   \n",
            "major               major               \n",
            "settlement          settlement          \n",
            "for                 for                 \n",
            "nearly              nearly              \n",
            "two                 two                 \n",
            "millennia           millennia           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKcPhEwqj95s",
        "outputId": "43681799-7c90-4e53-c927-595c2c3eda87"
      },
      "source": [
        "for word in new_sentence_words:\n",
        "  print('{0:20}{1:20}'.format(word,wordnet_lemmatizer.lemmatize(word, pos='n')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "London              London              \n",
            "is                  is                  \n",
            "the                 the                 \n",
            "capital             capital             \n",
            "and                 and                 \n",
            "largest             largest             \n",
            "city                city                \n",
            "of                  of                  \n",
            "England             England             \n",
            "and                 and                 \n",
            "the                 the                 \n",
            "United              United              \n",
            "Kingdom             Kingdom             \n",
            "with                with                \n",
            "a                   a                   \n",
            "population          population          \n",
            "of                  of                  \n",
            "around              around              \n",
            "8.8                 8.8                 \n",
            "million             million             \n",
            "[                   [                   \n",
            "1                   1                   \n",
            "]                   ]                   \n",
            "and                 and                 \n",
            "the                 the                 \n",
            "largest             largest             \n",
            "city                city                \n",
            "in                  in                  \n",
            "Western             Western             \n",
            "Europe              Europe              \n",
            "by                  by                  \n",
            "metropolitan        metropolitan        \n",
            "area                area                \n",
            "with                with                \n",
            "a                   a                   \n",
            "population          population          \n",
            "of                  of                  \n",
            "14.8                14.8                \n",
            "million             million             \n",
            "[                   [                   \n",
            "9                   9                   \n",
            "]                   ]                   \n",
            "[                   [                   \n",
            "note                note                \n",
            "1                   1                   \n",
            "]                   ]                   \n",
            "It                  It                  \n",
            "stands              stand               \n",
            "on                  on                  \n",
            "the                 the                 \n",
            "River               River               \n",
            "Thames              Thames              \n",
            "in                  in                  \n",
            "south-east          south-east          \n",
            "England             England             \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "head                head                \n",
            "of                  of                  \n",
            "a                   a                   \n",
            "50-mile             50-mile             \n",
            "80                  80                  \n",
            "km                  km                  \n",
            "estuary             estuary             \n",
            "down                down                \n",
            "to                  to                  \n",
            "the                 the                 \n",
            "North               North               \n",
            "Sea                 Sea                 \n",
            "and                 and                 \n",
            "has                 ha                  \n",
            "been                been                \n",
            "a                   a                   \n",
            "major               major               \n",
            "settlement          settlement          \n",
            "for                 for                 \n",
            "nearly              nearly              \n",
            "two                 two                 \n",
            "millennia           millennium          \n"
          ]
        }
      ]
    }
  ]
}